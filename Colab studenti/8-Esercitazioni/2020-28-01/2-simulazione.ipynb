{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from platform import machine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Normalizer, FunctionTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('archive/weather_features.csv')\n",
    "df"
   ],
   "id": "8956967e7dfecc5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1\n",
    "Si vuole predire il valore di 'weather_main' sulla base degli attributi presenti nel dataset.\n",
    "Dividere il dataset in modo che 2/3 degli elementi siano contenuti in un nuovo dataset “train” e\n",
    "1/3 nel dataset “test”.\n",
    "Eliminare gli attributi [\"dt_iso\",\"city_name\",\"weather_description\", \"weather_icon\",\"weather_id\",\n",
    "\"clouds_all\"]\n",
    "Convertire l’attributo 'weather_main' in numerico in maniera opportuna.\n",
    "Allenare il train con il modello Decision Tree e valutare l’accuracy ottenuta calcolata sia sul\n",
    "dataset train sia sul dataset test. Confrontare i risultati ottenuti con quelli ottenuti con una\n",
    "predizione basata sul modello Logistic Regression. Effettuare alcune considerazioni sui risultati\n",
    "ottenuti, tenendo in considerazione anche l’analisi della confusion matrix. (punti 4)"
   ],
   "id": "db17f3da2502ade3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(['dt_iso', 'city_name', 'weather_description', 'weather_icon', 'weather_id', 'clouds_all', 'weather_main'], axis=1)\n",
    "le = LabelEncoder()\n",
    "df['weather_target'] = le.fit_transform(df['weather_main'])\n",
    "y = df['weather_target']\n",
    "y"
   ],
   "id": "855e7bee3f92edb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:32:28.087072Z",
     "start_time": "2025-12-28T17:32:28.058478Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "45a74b71ed6b9596",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           temp  temp_min  temp_max  pressure  humidity  wind_speed  wind_deg  \\\n",
       "0       270.475   270.475   270.475      1001        77           1        62   \n",
       "1       270.475   270.475   270.475      1001        77           1        62   \n",
       "2       269.686   269.686   269.686      1002        78           0        23   \n",
       "3       269.686   269.686   269.686      1002        78           0        23   \n",
       "4       269.686   269.686   269.686      1002        78           0        23   \n",
       "...         ...       ...       ...       ...       ...         ...       ...   \n",
       "178391  287.760   287.150   288.150      1028        54           3        30   \n",
       "178392  285.760   285.150   286.150      1029        62           3        30   \n",
       "178393  285.150   285.150   285.150      1028        58           4        50   \n",
       "178394  284.150   284.150   284.150      1029        57           4        60   \n",
       "178395  283.970   282.150   285.150      1029        70           3        50   \n",
       "\n",
       "        rain_1h  rain_3h  snow_3h  \n",
       "0           0.0      0.0      0.0  \n",
       "1           0.0      0.0      0.0  \n",
       "2           0.0      0.0      0.0  \n",
       "3           0.0      0.0      0.0  \n",
       "4           0.0      0.0      0.0  \n",
       "...         ...      ...      ...  \n",
       "178391      0.0      0.0      0.0  \n",
       "178392      0.0      0.0      0.0  \n",
       "178393      0.0      0.0      0.0  \n",
       "178394      0.0      0.0      0.0  \n",
       "178395      0.0      0.0      0.0  \n",
       "\n",
       "[178396 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_3h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270.475</td>\n",
       "      <td>270.475</td>\n",
       "      <td>270.475</td>\n",
       "      <td>1001</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270.475</td>\n",
       "      <td>270.475</td>\n",
       "      <td>270.475</td>\n",
       "      <td>1001</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269.686</td>\n",
       "      <td>269.686</td>\n",
       "      <td>269.686</td>\n",
       "      <td>1002</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269.686</td>\n",
       "      <td>269.686</td>\n",
       "      <td>269.686</td>\n",
       "      <td>1002</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.686</td>\n",
       "      <td>269.686</td>\n",
       "      <td>269.686</td>\n",
       "      <td>1002</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178391</th>\n",
       "      <td>287.760</td>\n",
       "      <td>287.150</td>\n",
       "      <td>288.150</td>\n",
       "      <td>1028</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178392</th>\n",
       "      <td>285.760</td>\n",
       "      <td>285.150</td>\n",
       "      <td>286.150</td>\n",
       "      <td>1029</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178393</th>\n",
       "      <td>285.150</td>\n",
       "      <td>285.150</td>\n",
       "      <td>285.150</td>\n",
       "      <td>1028</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178394</th>\n",
       "      <td>284.150</td>\n",
       "      <td>284.150</td>\n",
       "      <td>284.150</td>\n",
       "      <td>1029</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178395</th>\n",
       "      <td>283.970</td>\n",
       "      <td>282.150</td>\n",
       "      <td>285.150</td>\n",
       "      <td>1029</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178396 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:32:29.017777Z",
     "start_time": "2025-12-28T17:32:28.250845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_train)\n",
    "acc_dt_train = accuracy_score(y_train, y_pred)\n",
    "print(f\"--- Decision Tree ---\")\n",
    "print(f' Accuracy dt train: {acc_dt_train}')\n",
    "y_pred = dt.predict(X_test)\n",
    "acc_dt_test = accuracy_score(y_test, y_pred)\n",
    "print(f' Accuracy dt test: {acc_dt_test}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "10521db8fb094a97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Decision Tree ---\n",
      " Accuracy dt train: 0.98399498012968\n",
      " Accuracy dt test: 0.6366632127872807\n",
      "[[18522  7875    90    63   239    70   301     0    12    11    57]\n",
      " [ 7913 13625   216    28   208    30   349     0     3    17   122]\n",
      " [   75   170    38     1    42     2    90   160     1     2     7]\n",
      " [   66    25     1    15     2     2     3     5     0     0     0]\n",
      " [  181   192    43     4   163     7   217    16     0     7     1]\n",
      " [   57    42     0     2    12    15     5    10     0     0     0]\n",
      " [  262   332   110     0   256    11   146   130     0     6     8]\n",
      " [    0     0   326    12    35     9   242  4929     0    31   138]\n",
      " [    7     2     0     0     0     0     0     0     0     0     0]\n",
      " [    8    12     9     0     4     0    10    27     0    17     0]\n",
      " [   65   114     6     0     1     0    12   151     0     0    11]]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:32:31.191365Z",
     "start_time": "2025-12-28T17:32:29.133295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_train)\n",
    "acc_lr_train = accuracy_score(y_train, y_pred)\n",
    "print(f\"--- Logistic Regression ---\")\n",
    "print(f' Accuracy lr train: {acc_lr_train}')\n",
    "y_pred = lr.predict(X_test)\n",
    "acc_lr_test = accuracy_score(y_test, y_pred)\n",
    "print(f' Accuracy lr test: {acc_lr_test}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "a15a94dd1f861e70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      " Accuracy lr train: 0.4798326709893328\n",
      " Accuracy lr test: 0.4796589152553889\n",
      "[[18900  8340     0     0     0     0     0     0     0     0     0]\n",
      " [13174  9337     0     0     0     0     0     0     0     0     0]\n",
      " [   70   518     0     0     0     0     0     0     0     0     0]\n",
      " [   84    35     0     0     0     0     0     0     0     0     0]\n",
      " [   58   773     0     0     0     0     0     0     0     0     0]\n",
      " [   45    98     0     0     0     0     0     0     0     0     0]\n",
      " [   65  1196     0     0     0     0     0     0     0     0     0]\n",
      " [ 1155  4566     0     0     0     0     0     1     0     0     0]\n",
      " [    7     2     0     0     0     0     0     0     0     0     0]\n",
      " [    6    81     0     0     0     0     0     0     0     0     0]\n",
      " [  148   212     0     0     0     0     0     0     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieledavena/Uni/Big Data/BData/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Il Decision Tree supera la Logistic Regression sul Test set (0.63 vs 0.50), dimostrando che la relazione tra le features e il tipo di meteo non è lineare. Tuttavia, la LR soffre meno di overfitting.",
   "id": "e2413d40e4365c4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2\n",
    "Confrontare l’accuratezza ottenuta nel punto precedente con l’accuratezza che si ottiene con\n",
    "un una 10 Fold cross validation. (punti 1)"
   ],
   "id": "24c4db7768e24c9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:32:34.836527Z",
     "start_time": "2025-12-28T17:32:31.275064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cross_val = cross_val_score(dt, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Cross val: {cross_val.mean()}')"
   ],
   "id": "130345f022890411",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieledavena/Uni/Big Data/BData/lib/python3.13/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val: 0.5253760381400322\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3\n",
    "Utilizzare la funzione Normalizer per normalizzare i valori del dataset e confrontare se\n",
    "l’accuratezza ottenuta con il Decision Tree Classifier migliora (punti 3)."
   ],
   "id": "4920192d4b451c76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:32:36.532276Z",
     "start_time": "2025-12-28T17:32:34.863865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "norm = Normalizer()\n",
    "X = norm.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_train)\n",
    "acc_dt_train = accuracy_score(y_train, y_pred)\n",
    "print(f\"--- Decision Tree ---\")\n",
    "print(f' Accuracy dt train: {acc_dt_train}')\n",
    "y_pred = dt.predict(X_test)\n",
    "acc_dt_test = accuracy_score(y_test, y_pred)\n",
    "print(f' Accuracy dt test: {acc_dt_test}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "96e49391448cb42c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Decision Tree ---\n",
      " Accuracy dt train: 0.98399498012968\n",
      " Accuracy dt test: 0.6210528103820218\n",
      "[[17964  8416    62    68   240    88   309     0     9    16    68]\n",
      " [ 8213 13307   184    31   245    51   331     0    12     7   130]\n",
      " [   72   181    27     0    46     3    92   158     0     1     8]\n",
      " [   60    38     1    12     2     0     0     6     0     0     0]\n",
      " [  199   179    42     4   162     8   209    16     0    11     1]\n",
      " [   56    51     1     1    10     9     5    10     0     0     0]\n",
      " [  287   341   100     1   246    13   130   130     0     6     7]\n",
      " [    0     0   346    13    39     9   232  4928     0    27   128]\n",
      " [    6     3     0     0     0     0     0     0     0     0     0]\n",
      " [   11     9     6     0     4     0    10    33     0    14     0]\n",
      " [   59   118     8     1     2     2    10   150     0     1     9]]\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4\n",
    "Creare una pipeline con trasformatori PCA (si scelgano 5 attributi) e poi Normalizer. Si usi\n",
    "come modello il Decision Tree Classifier (punti 2) [2 punti ulteriori se gli attributi della PCA\n",
    "sono aggiunti agli attributi del dataset]"
   ],
   "id": "5dffd649d5974267"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:32:39.304696Z",
     "start_time": "2025-12-28T17:32:36.558672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "identity_transformer = FunctionTransformer(lambda x: x, validate=False)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    (\"original_features\", identity_transformer),  # Ramo 1: Dati originali\n",
    "    (\"pca_features\", PCA(n_components=5))       # Ramo 2: 5 attributi PCA\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('combined_features', combined_features),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_train)\n",
    "acc_PCA_dt_train = accuracy_score(y_train, y_pred)\n",
    "print(f\"--- PCA COMBINED ---\")\n",
    "print(f' Accuracy dt train: {acc_dt_train}')\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc_PCA_dt_test = accuracy_score(y_test, y_pred)\n",
    "print(f' Accuracy dt test: {acc_PCA_dt_test}')"
   ],
   "id": "91aa0c38e48efe83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCA COMBINED ---\n",
      " Accuracy dt train: 0.98399498012968\n",
      " Accuracy dt test: 0.6265223964260842\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PCA(n_components=5): Estrae le 5 componenti che spiegano la maggior varianza. Aggiungendole al dataset originale, stiamo fornendo al Decision Tree delle \"meta-informazioni\" riassuntive che potrebbero aiutarlo a fare tagli migliori.",
   "id": "35ae48321b3b1e2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5\n",
    "Utilizzare la funzione di gridSearchCV sulla pipeline per modificare il numero di attributi\n",
    "selezionati dalla PCA e alcuni parametri a piacere del classificatore. Verificare se l’accuratezza\n",
    "che si ottiene con la nuova configurazione supera quella standard ottenuta al punto 1 (punti 4)"
   ],
   "id": "2cfdda2f8629b00b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:33:21.684862Z",
     "start_time": "2025-12-28T17:32:39.322861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid ={\n",
    "    'combined_features__pca_features__n_components' : [3, 4, 5, 6, 7],\n",
    "    'dt__criterion' : ['gini', 'entropy'],\n",
    "    'dt__max_depth' : [3, 5, 7],\n",
    "}\n",
    "gs = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_test)\n",
    "acc_gs = accuracy_score(y_test, y_pred)\n",
    "print(f\" Accuracy grid search test: {acc_gs}\")\n",
    "print(f'Best params: {gs.best_params_}')\n",
    "print(f'Best score: {gs.best_score_}')\n",
    "\n",
    "print(f\"\\n--- Confronto ---\")\n",
    "print(f\"Accuracy Standard (Punto 1): {acc_dt_test:.4f}\") # Assicurati che questa var esista ancora\n",
    "print(f\"Accuracy Ottimizzata: {acc_gs:.4f}\")\n",
    "\n",
    "if acc_gs > acc_dt_test:\n",
    "    print(\"RISULTATO: La nuova configurazione ha migliorato le performance!\")\n",
    "else:\n",
    "    print(\"RISULTATO: Non c'è stato un miglioramento (o l'overfitting è stato ridotto a scapito dell'accuracy pura).\")"
   ],
   "id": "bb807c869a6efdb3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieledavena/Uni/Big Data/BData/lib/python3.13/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy grid search test: 0.643848414329636\n",
      "Best params: {'combined_features__pca_features__n_components': 5, 'dt__criterion': 'gini', 'dt__max_depth': 7}\n",
      "Best score: 0.6433884124660112\n",
      "\n",
      "--- Confronto ---\n",
      "Accuracy Standard (Punto 1): 0.6211\n",
      "Accuracy Ottimizzata: 0.6438\n",
      "RISULTATO: La nuova configurazione ha migliorato le performance!\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6 NON POSSO FARLO; NON HO I DATASET",
   "id": "5a4afa55d80662ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7\n",
    "Si sperimenti una pipeline come quella del punto 4 dove al posto del classificatore si utilizzi\n",
    "un regressore lineare. Il risultato dovrà essere approssimato all’intero per il calcolo\n",
    "dell’accuratezza (punti 2)."
   ],
   "id": "afc1cb07b41fff45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:36:59.221223Z",
     "start_time": "2025-12-28T17:36:59.057516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "identity_transformer = FunctionTransformer(lambda x: x, validate=False)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    (\"original_features\", identity_transformer),  # Ramo 1: Dati originali\n",
    "    (\"pca_features\", PCA(n_components=5))       # Ramo 2: 5 attributi PCA\n",
    "])\n",
    "\n",
    "pipeline_reg = Pipeline([\n",
    "    ('combined_features', combined_features),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('dt', LinearRegression()),\n",
    "])\n",
    "\n",
    "pipeline_reg.fit(X_train, y_train)\n",
    "y_pred = np.round(pipeline_reg.predict(X_train)).astype(int)\n",
    "acc_PCA_reg_train = accuracy_score(y_train, y_pred)\n",
    "print(f\"--- PCA COMBINED REG ---\")\n",
    "print(f' Accuracy reg train: {acc_PCA_reg_train}')\n",
    "y_pred = np.round(pipeline.predict(X_test)).astype(int)\n",
    "acc_PCA_reg_test = accuracy_score(y_test, y_pred)\n",
    "print(f' Accuracy dt test: {acc_PCA_reg_test}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "eda586ef4982c101",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCA COMBINED REG ---\n",
      " Accuracy reg train: 0.31612633340305374\n",
      " Accuracy dt test: 0.6265223964260842\n",
      "[[18169  8145    95    73   269    72   333     0    10    11    63]\n",
      " [ 8175 13427   193    24   211    43   330     0     9     7    92]\n",
      " [   88   174    35     1    35     1    87   159     0     1     7]\n",
      " [   66    28     3    13     2     0     1     6     0     0     0]\n",
      " [  192   192    41     2   157     2   224    15     0     6     0]\n",
      " [   58    44     1     1    12    11     5    11     0     0     0]\n",
      " [  284   342   106     0   246     7   130   136     0     4     6]\n",
      " [    0     1   339    14    38     8   249  4923     0    26   124]\n",
      " [    5     3     0     0     0     1     0     0     0     0     0]\n",
      " [   11    14     6     0     4     0    11    30     0    10     1]\n",
      " [   61   121     7     2     0     0    12   148     0     0     9]]\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "La linear regression dovrebbe avere risultati peggiori perché noi stiamo facendo classificazione, ma lui la vede come una regressione, quindi pensa che cloud(2) è il doppio di soleggiato (1), ma in realtà sono cose che non c'entrano un cazzo",
   "id": "a1f396cc891d5ce0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3dcac3eebb99cc35",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
