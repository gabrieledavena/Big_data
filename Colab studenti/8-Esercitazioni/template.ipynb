{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6905fd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fc730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import base\n",
    "from sklearn import calibration\n",
    "from sklearn import cluster\n",
    "from sklearn import compose\n",
    "from sklearn import covariance\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn import decomposition\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import dummy\n",
    "from sklearn import ensemble\n",
    "from sklearn import exceptions\n",
    "from sklearn import experimental\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import feature_selection\n",
    "from sklearn import gaussian_process\n",
    "from sklearn import impute\n",
    "from sklearn import inspection\n",
    "from sklearn import isotonic\n",
    "from sklearn import kernel_approximation\n",
    "from sklearn import kernel_ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn import manifold\n",
    "from sklearn import metrics\n",
    "from sklearn import mixture\n",
    "from sklearn import model_selection\n",
    "from sklearn import multiclass\n",
    "from sklearn import multioutput\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import random_projection\n",
    "from sklearn import semi_supervised\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6461304",
   "metadata": {},
   "source": [
    "## Listing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b678e",
   "metadata": {},
   "source": [
    "- `sklearn`\n",
    "  - config_context\n",
    "  - get_config\n",
    "  - set_config\n",
    "  - show_versions\n",
    "- `base`:\n",
    "  - BaseEstimator\n",
    "  - BiclusterMixin\n",
    "  - ClassNamePrefixFeaturesOutMixin\n",
    "  - ClassifierMixin\n",
    "  - ClusterMixin\n",
    "  - DensityMixin\n",
    "  - MetaEstimatorMixin\n",
    "  - OneToOneFeatureMixin\n",
    "  - OutlierMixin\n",
    "  - RegressorMixin\n",
    "  - TransformerMixin\n",
    "  - clone\n",
    "  - is_classifier\n",
    "  - is_clusterer\n",
    "  - is_regressor\n",
    "  - is_outlier_detector\n",
    "- `calibration`\n",
    "  - CalibratedClassifierCV\n",
    "  - calibration_curve\n",
    "  - CalibrationDisplay\n",
    "- `cluster`\n",
    "  - AffinityPropagation\n",
    "  - AgglomerativeClustering\n",
    "  - Birch\n",
    "  - BisectingKMeans\n",
    "  - DBSCAN\n",
    "  - FeatureAgglomeration\n",
    "  - HDBSCAN\n",
    "  - KMeans\n",
    "  - MeanShift\n",
    "  - MiniBatchKMeans\n",
    "  - OPTICS\n",
    "  - SpectralBiclustering\n",
    "  - SpectralClustering\n",
    "  - SpectralCoclustering\n",
    "  - affinity_propagation\n",
    "  - cluster_optics_dbscan\n",
    "  - cluster_optics_xi\n",
    "  - compute_optics_graph\n",
    "  - dbscan\n",
    "  - estimate_bandwidth\n",
    "  - k_means\n",
    "  - kmeans_plusplus\n",
    "  - mean_shift\n",
    "  - spectral_clustering\n",
    "  - ward_tree\n",
    "- `compose`\n",
    "  - ColumnTransformer\n",
    "  - TransformedTargetRegressor\n",
    "  - make_column_selector\n",
    "  - make_column_transformer\n",
    "- `covariance`\n",
    "  - EllipticEnvelope\n",
    "  - EmpiricalCovariance\n",
    "  - GraphicalLasso\n",
    "  - GraphicalLassoCV\n",
    "  - LedoitWolf\n",
    "  - MinCovDet\n",
    "  - OAS\n",
    "  - ShrunkCovariance\n",
    "  - empirical_covariance\n",
    "  - graphical_lasso\n",
    "  - ledoit_wolf\n",
    "  - ledoit_wolf_shrinkage\n",
    "  - oas\n",
    "  - shrunk_covariance\n",
    "- `cross_decomposition`\n",
    "  - CCA\n",
    "  - PLSCanonical\n",
    "  - PLSRegression\n",
    "  - PLSSVD\n",
    "- `datasets`\n",
    "  - clear_data_home\n",
    "  - dump_svmlight_file\n",
    "  - fetch_20newsgroups\n",
    "  - fetch_20newsgroups_vectorized\n",
    "  - fetch_california_housing\n",
    "  - fetch_covtype\n",
    "  - fetch_file\n",
    "  - fetch_kddcup99\n",
    "  - fetch_lfw_pairs\n",
    "  - fetch_lfw_people\n",
    "  - fetch_olivetti_faces\n",
    "  - fetch_openml\n",
    "  - fetch_rcv1\n",
    "  - fetch_species_distributions\n",
    "  - get_data_home\n",
    "  - load_breast_cancer\n",
    "  - load_diabetes\n",
    "  - load_digits\n",
    "  - load_files\n",
    "  - load_iris\n",
    "  - load_linnerud\n",
    "  - load_sample_image\n",
    "  - load_sample_images\n",
    "  - load_svmlight_file\n",
    "  - load_svmlight_files\n",
    "  - load_wine\n",
    "  - make_biclusters\n",
    "  - make_blobs\n",
    "  - make_checkerboard\n",
    "  - make_circles\n",
    "  - make_classification\n",
    "  - make_friedman1\n",
    "  - make_friedman2\n",
    "  - make_friedman3\n",
    "  - make_gaussian_quantiles\n",
    "  - make_hastie_10_2\n",
    "  - make_low_rank_matrix\n",
    "  - make_moons\n",
    "  - make_multilabel_classification\n",
    "  - make_regression\n",
    "  - make_s_curve\n",
    "  - make_sparse_coded_signal\n",
    "  - make_sparse_spd_matrix\n",
    "  - make_sparse_uncorrelated\n",
    "  - make_spd_matrix\n",
    "  - make_swiss_roll\n",
    "- `decomposition`\n",
    "  - DictionaryLearning\n",
    "  - FactorAnalysis\n",
    "  - FastICA\n",
    "  - IncrementalPCA\n",
    "  - KernelPCA\n",
    "  - LatentDirichletAllocation\n",
    "  - MiniBatchDictionaryLearning\n",
    "  - MiniBatchNMF\n",
    "  - MiniBatchSparsePCA\n",
    "  - NMF\n",
    "  - PCA\n",
    "  - SparseCoder\n",
    "  - SparsePCA\n",
    "  - TruncatedSVD\n",
    "  - dict_learning\n",
    "  - dict_learning_online\n",
    "  - fastica\n",
    "  - non_negative_factorization\n",
    "  - sparse_encode\n",
    "- `discriminant_analysis`\n",
    "  - LinearDiscriminantAnalysis\n",
    "  - QuadraticDiscriminantAnalysis\n",
    "- `dummy`\n",
    "  - DummyClassifier\n",
    "  - DummyRegressor\n",
    "- `ensemble`\n",
    "  - AdaBoostClassifier\n",
    "  - AdaBoostRegressor\n",
    "  - BaggingClassifier\n",
    "  - BaggingRegressor\n",
    "  - ExtraTreesClassifier\n",
    "  - ExtraTreesRegressor\n",
    "  - GradientBoostingClassifier\n",
    "  - GradientBoostingRegressor\n",
    "  - HistGradientBoostingClassifier\n",
    "  - HistGradientBoostingRegressor\n",
    "  - IsolationForest\n",
    "  - RandomForestClassifier\n",
    "  - RandomForestRegressor\n",
    "  - RandomTreesEmbedding\n",
    "  - StackingClassifier\n",
    "  - StackingRegressor\n",
    "  - VotingClassifier\n",
    "  - VotingRegressor\n",
    "- `exceptions`\n",
    "  - ConvergenceWarning\n",
    "  - DataConversionWarning\n",
    "  - DataDimensionalityWarning\n",
    "  - EfficiencyWarning\n",
    "  - FitFailedWarning\n",
    "  - InconsistentVersionWarning\n",
    "  - NotFittedError\n",
    "  - UndefinedMetricWarning\n",
    "  - EstimatorCheckFailedWarning\n",
    "- `experimental`\n",
    "  - enable_halving_search_cv\n",
    "  - enable_iterative_imputer\n",
    "- `feature_extraction`\n",
    "  - DictVectorizer\n",
    "  - FeatureHasher\n",
    "  - PatchExtractor\n",
    "  - extract_patches_2d\n",
    "  - grid_to_graph\n",
    "  - img_to_graph\n",
    "  - reconstruct_from_patches_2d\n",
    "  - CountVectorizer\n",
    "  - HashingVectorizer\n",
    "  - TfidfTransformer\n",
    "  - TfidfVectorizer\n",
    "- `feature_selection`\n",
    "  - GenericUnivariateSelect\n",
    "  - RFE\n",
    "  - RFECV\n",
    "  - SelectFdr\n",
    "  - SelectFpr\n",
    "  - SelectFromModel\n",
    "  - SelectFwe\n",
    "  - SelectKBest\n",
    "  - SelectPercentile\n",
    "  - SelectorMixin\n",
    "  - SequentialFeatureSelector\n",
    "  - VarianceThreshold\n",
    "  - chi2\n",
    "  - f_classif\n",
    "  - f_regression\n",
    "  - mutual_info_classif\n",
    "  - mutual_info_regression\n",
    "  - r_regression\n",
    "- `gaussian_process`\n",
    "  - GaussianProcessClassifier\n",
    "  - GaussianProcessRegressor\n",
    "  - CompoundKernel\n",
    "  - ConstantKernel\n",
    "  - DotProduct\n",
    "  - ExpSineSquared\n",
    "  - Exponentiation\n",
    "  - Hyperparameter\n",
    "  - Kernel\n",
    "  - Matern\n",
    "  - PairwiseKernel\n",
    "  - Product\n",
    "  - RBF\n",
    "  - RationalQuadratic\n",
    "  - Sum\n",
    "  - WhiteKernel\n",
    "- `impute`\n",
    "  - IterativeImputer\n",
    "  - KNNImputer\n",
    "  - MissingIndicator\n",
    "  - SimpleImputer\n",
    "- `inspection`\n",
    "  - partial_dependence\n",
    "  - permutation_importance\n",
    "  - DecisionBoundaryDisplay\n",
    "  - PartialDependenceDisplay\n",
    "- `isotonic`\n",
    "  - IsotonicRegression\n",
    "  - check_increasing\n",
    "  - isotonic_regression\n",
    "- `kernel_approximation`\n",
    "  - AdditiveChi2Sampler\n",
    "  - Nystroem\n",
    "  - PolynomialCountSketch\n",
    "  - RBFSampler\n",
    "  - SkewedChi2Sampler\n",
    "- `kernel_ridge`\n",
    "  - KernelRidge\n",
    "- `linear_model`\n",
    "  - LogisticRegression\n",
    "  - LogisticRegressionCV\n",
    "  - PassiveAggressiveClassifier\n",
    "  - Perceptron\n",
    "  - RidgeClassifier\n",
    "  - RidgeClassifierCV\n",
    "  - SGDClassifier\n",
    "  - SGDOneClassSVM\n",
    "  - LinearRegression\n",
    "  - Ridge\n",
    "  - RidgeCV\n",
    "  - SGDRegressor\n",
    "  - ElasticNet\n",
    "  - ElasticNetCV\n",
    "  - Lars\n",
    "  - LarsCV\n",
    "  - Lasso\n",
    "  - LassoCV\n",
    "  - LassoLars\n",
    "  - LassoLarsCV\n",
    "  - LassoLarsIC\n",
    "  - OrthogonalMatchingPursuit\n",
    "  - OrthogonalMatchingPursuitCV\n",
    "  - ARDRegression\n",
    "  - BayesianRidge\n",
    "  - MultiTaskElasticNet\n",
    "  - MultiTaskElasticNetCV\n",
    "  - MultiTaskLasso\n",
    "  - MultiTaskLassoCV\n",
    "  - HuberRegressor\n",
    "  - QuantileRegressor\n",
    "  - RANSACRegressor\n",
    "  - TheilSenRegressor\n",
    "  - GammaRegressor\n",
    "  - PoissonRegressor\n",
    "  - TweedieRegressor\n",
    "  - PassiveAggressiveRegressor\n",
    "  - enet_path\n",
    "  - lars_path\n",
    "  - lars_path_gram\n",
    "  - lasso_path\n",
    "  - orthogonal_mp\n",
    "  - orthogonal_mp_gram\n",
    "  - ridge_regression\n",
    "- `manifold`\n",
    "  - Isomap\n",
    "  - LocallyLinearEmbedding\n",
    "  - MDS\n",
    "  - SpectralEmbedding\n",
    "  - TSNE\n",
    "  - locally_linear_embedding\n",
    "  - smacof\n",
    "  - spectral_embedding\n",
    "  - trustworthiness\n",
    "- `metrics`\n",
    "  - check_scoring\n",
    "  - get_scorer\n",
    "  - get_scorer_names\n",
    "  - make_scorer\n",
    "  - accuracy_score\n",
    "  - auc\n",
    "  - average_precision_score\n",
    "  - balanced_accuracy_score\n",
    "  - brier_score_loss\n",
    "  - class_likelihood_ratios\n",
    "  - classification_report\n",
    "  - cohen_kappa_score\n",
    "  - confusion_matrix\n",
    "  - d2_log_loss_score\n",
    "  - dcg_score\n",
    "  - det_curve\n",
    "  - f1_score\n",
    "  - fbeta_score\n",
    "  - hamming_loss\n",
    "  - hinge_loss\n",
    "  - jaccard_score\n",
    "  - log_loss\n",
    "  - matthews_corrcoef\n",
    "  - multilabel_confusion_matrix\n",
    "  - ndcg_score\n",
    "  - precision_recall_curve\n",
    "  - precision_recall_fscore_support\n",
    "  - precision_score\n",
    "  - recall_score\n",
    "  - roc_auc_score\n",
    "  - roc_curve\n",
    "  - top_k_accuracy_score\n",
    "  - zero_one_loss\n",
    "  - d2_absolute_error_score\n",
    "  - d2_pinball_score\n",
    "  - d2_tweedie_score\n",
    "  - explained_variance_score\n",
    "  - max_error\n",
    "  - mean_absolute_error\n",
    "  - mean_absolute_percentage_error\n",
    "  - mean_gamma_deviance\n",
    "  - mean_pinball_loss\n",
    "  - mean_poisson_deviance\n",
    "  - mean_squared_error\n",
    "  - mean_squared_log_error\n",
    "  - mean_tweedie_deviance\n",
    "  - median_absolute_error\n",
    "  - r2_score\n",
    "  - root_mean_squared_error\n",
    "  - root_mean_squared_log_error\n",
    "  - coverage_error\n",
    "  - label_ranking_average_precision_score\n",
    "  - label_ranking_loss\n",
    "  - adjusted_mutual_info_score\n",
    "  - adjusted_rand_score\n",
    "  - calinski_harabasz_score\n",
    "  - contingency_matrix\n",
    "  - pair_confusion_matrix\n",
    "  - completeness_score\n",
    "  - davies_bouldin_score\n",
    "  - fowlkes_mallows_score\n",
    "  - homogeneity_completeness_v_measure\n",
    "  - homogeneity_score\n",
    "  - mutual_info_score\n",
    "  - normalized_mutual_info_score\n",
    "  - rand_score\n",
    "  - silhouette_samples\n",
    "  - silhouette_score\n",
    "  - v_measure_score\n",
    "  - consensus_score\n",
    "  - DistanceMetric\n",
    "  - additive_chi2_kernel\n",
    "  - chi2_kernel\n",
    "  - cosine_distances\n",
    "  - cosine_similarity\n",
    "  - distance_metrics\n",
    "  - euclidean_distances\n",
    "  - haversine_distances\n",
    "  - kernel_metrics\n",
    "  - laplacian_kernel\n",
    "  - linear_kernel\n",
    "  - manhattan_distances\n",
    "  - nan_euclidean_distances\n",
    "  - paired_cosine_distances\n",
    "  - paired_distances\n",
    "  - paired_euclidean_distances\n",
    "  - paired_manhattan_distances\n",
    "  - pairwise_kernels\n",
    "  - polynomial_kernel\n",
    "  - rbf_kernel\n",
    "  - sigmoid_kernel\n",
    "  - pairwise_distances\n",
    "  - pairwise_distances_argmin\n",
    "  - pairwise_distances_argmin_min\n",
    "  - pairwise_distances_chunked\n",
    "  - ConfusionMatrixDisplay\n",
    "  - DetCurveDisplay\n",
    "  - PrecisionRecallDisplay\n",
    "  - PredictionErrorDisplay\n",
    "  - RocCurveDisplay\n",
    "- `mixture`\n",
    "  - BayesianGaussianMixture\n",
    "  - GaussianMixture\n",
    "- `model_selection`\n",
    "  - GroupKFold\n",
    "  - GroupShuffleSplit\n",
    "  - KFold\n",
    "  - LeaveOneGroupOut\n",
    "  - LeaveOneOut\n",
    "  - LeavePGroupsOut\n",
    "  - LeavePOut\n",
    "  - PredefinedSplit\n",
    "  - RepeatedKFold\n",
    "  - RepeatedStratifiedKFold\n",
    "  - ShuffleSplit\n",
    "  - StratifiedGroupKFold\n",
    "  - StratifiedKFold\n",
    "  - StratifiedShuffleSplit\n",
    "  - TimeSeriesSplit\n",
    "  - check_cv\n",
    "  - train_test_split\n",
    "  - GridSearchCV\n",
    "  - HalvingGridSearchCV\n",
    "  - HalvingRandomSearchCV\n",
    "  - ParameterGrid\n",
    "  - ParameterSampler\n",
    "  - RandomizedSearchCV\n",
    "  - FixedThresholdClassifier\n",
    "  - TunedThresholdClassifierCV\n",
    "  - cross_val_predict\n",
    "  - cross_val_score\n",
    "  - cross_validate\n",
    "  - learning_curve\n",
    "  - permutation_test_score\n",
    "  - validation_curve\n",
    "  - LearningCurveDisplay\n",
    "  - ValidationCurveDisplay\n",
    "- `multiclass`\n",
    "  - OneVsOneClassifier\n",
    "  - OneVsRestClassifier\n",
    "  - OutputCodeClassifier\n",
    "- `multioutput`\n",
    "  - ClassifierChain\n",
    "  - MultiOutputClassifier\n",
    "  - MultiOutputRegressor\n",
    "  - RegressorChain\n",
    "- `naive_bayes`\n",
    "  - BernoulliNB\n",
    "  - CategoricalNB\n",
    "  - ComplementNB\n",
    "  - GaussianNB\n",
    "  - MultinomialNB\n",
    "- `neighbors`\n",
    "  - BallTree\n",
    "  - KDTree\n",
    "  - KNeighborsClassifier\n",
    "  - KNeighborsRegressor\n",
    "  - KNeighborsTransformer\n",
    "  - KernelDensity\n",
    "  - LocalOutlierFactor\n",
    "  - NearestCentroid\n",
    "  - NearestNeighbors\n",
    "  - NeighborhoodComponentsAnalysis\n",
    "  - RadiusNeighborsClassifier\n",
    "  - RadiusNeighborsRegressor\n",
    "  - RadiusNeighborsTransformer\n",
    "  - kneighbors_graph\n",
    "  - radius_neighbors_graph\n",
    "  - sort_graph_by_row_values\n",
    "- `neural_network`\n",
    "  - BernoulliRBM\n",
    "  - MLPClassifier\n",
    "  - MLPRegressor\n",
    "- `pipeline`\n",
    "  - FeatureUnion\n",
    "  - Pipeline\n",
    "  - make_pipeline\n",
    "  - make_union\n",
    "- `preprocessing`\n",
    "  - Binarizer\n",
    "  - FunctionTransformer\n",
    "  - KBinsDiscretizer\n",
    "  - KernelCenterer\n",
    "  - LabelBinarizer\n",
    "  - LabelEncoder\n",
    "  - MaxAbsScaler\n",
    "  - MinMaxScaler\n",
    "  - MultiLabelBinarizer\n",
    "  - Normalizer\n",
    "  - OneHotEncoder\n",
    "  - OrdinalEncoder\n",
    "  - PolynomialFeatures\n",
    "  - PowerTransformer\n",
    "  - QuantileTransformer\n",
    "  - RobustScaler\n",
    "  - SplineTransformer\n",
    "  - StandardScaler\n",
    "  - TargetEncoder\n",
    "  - add_dummy_feature\n",
    "  - binarize\n",
    "  - label_binarize\n",
    "  - maxabs_scale\n",
    "  - minmax_scale\n",
    "  - normalize\n",
    "  - power_transform\n",
    "  - quantile_transform\n",
    "  - robust_scale\n",
    "  - scale\n",
    "- `random_projection`\n",
    "  - GaussianRandomProjection\n",
    "  - SparseRandomProjection\n",
    "  - johnson_lindenstrauss_min_dim\n",
    "- `semi_supervised`\n",
    "  - LabelPropagation\n",
    "  - LabelSpreading\n",
    "  - SelfTrainingClassifier\n",
    "- `svm`\n",
    "  - LinearSVC\n",
    "  - LinearSVR\n",
    "  - NuSVC\n",
    "  - NuSVR\n",
    "  - OneClassSVM\n",
    "  - SVC\n",
    "  - SVR\n",
    "  - l1_min_c\n",
    "- `tree`\n",
    "  - DecisionTreeClassifier\n",
    "  - DecisionTreeRegressor\n",
    "  - ExtraTreeClassifier\n",
    "  - ExtraTreeRegressor\n",
    "  - export_graphviz\n",
    "  - export_text\n",
    "  - plot_tree\n",
    "- `utils`\n",
    "  - Bunch\n",
    "  - _safe_indexing\n",
    "  - as_float_array\n",
    "  - assert_all_finite\n",
    "  - deprecated\n",
    "  - estimator_html_repr\n",
    "  - gen_batches\n",
    "  - gen_even_slices\n",
    "  - indexable\n",
    "  - murmurhash3_32\n",
    "  - resample\n",
    "  - safe_mask\n",
    "  - safe_sqr\n",
    "  - shuffle\n",
    "  - Tags\n",
    "  - InputTags\n",
    "  - TargetTags\n",
    "  - ClassifierTags\n",
    "  - RegressorTags\n",
    "  - TransformerTags\n",
    "  - get_tags\n",
    "  - check_X_y\n",
    "  - check_array\n",
    "  - check_consistent_length\n",
    "  - check_random_state\n",
    "  - check_scalar\n",
    "  - check_is_fitted\n",
    "  - check_memory\n",
    "  - check_symmetric\n",
    "  - column_or_1d\n",
    "  - has_fit_parameter\n",
    "  - validate_data\n",
    "  - available_if\n",
    "  - compute_class_weight\n",
    "  - compute_sample_weight\n",
    "  - is_multilabel\n",
    "  - type_of_target\n",
    "  - unique_labels\n",
    "  - density\n",
    "  - fast_logdet\n",
    "  - randomized_range_finder\n",
    "  - randomized_svd\n",
    "  - safe_sparse_dot\n",
    "  - weighted_mode\n",
    "  - incr_mean_variance_axis\n",
    "  - inplace_column_scale\n",
    "  - inplace_csr_column_scale\n",
    "  - inplace_row_scale\n",
    "  - inplace_swap_column\n",
    "  - inplace_swap_row\n",
    "  - mean_variance_axis\n",
    "  - inplace_csr_row_normalize_l1\n",
    "  - inplace_csr_row_normalize_l2\n",
    "  - single_source_shortest_path_length\n",
    "  - sample_without_replacement\n",
    "  - min_pos\n",
    "  - MetadataRequest\n",
    "  - MetadataRouter\n",
    "  - MethodMapping\n",
    "  - get_routing_for_object\n",
    "  - process_routing\n",
    "  - all_displays\n",
    "  - all_estimators\n",
    "  - all_functions\n",
    "  - check_estimator\n",
    "  - parametrize_with_checks\n",
    "  - estimator_checks_generator\n",
    "  - Parallel\n",
    "  - delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec67c9",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9a808",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb962aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filepath', sep=',')  # header=0 is default\n",
    "# or\n",
    "df = pd.read_csv('filepath', sep=',', names=['feature1_name', 'feature2_name', 'feature3_name'], header=None)\n",
    "# or\n",
    "df = pd.read_csv('filepath', sep=',', index_col=0)  # takes first column as index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee90968",
   "metadata": {},
   "source": [
    "## Rows, cols and null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc59e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', df.shape)\n",
    "print('Rows (instances):', df.shape[0])\n",
    "print('Cols (features + target):', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be42a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# or\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows which contain missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1560f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())\n",
    "# In each column the substitution is done with that feature's mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4368b4",
   "metadata": {},
   "source": [
    "## Check balance of target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38185c2",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ece329",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'yes': 1, 'no': 0}\n",
    "\n",
    "df['feature'] = df['feature'].map(mapping)\n",
    "# or\n",
    "df['feature'] = df['feature'].str.lower().map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609457e",
   "metadata": {},
   "source": [
    "## Discretization and Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b437ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 61, 27, 21, 23, 37, 31, 59, 45, 41, 32]\n",
    "bins = [18, 25, 35, 60, 100] # 5 values => 4 bins/intervals\n",
    "groups_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "\n",
    "binned_ages = pd.cut(ages, bins)\n",
    "# or\n",
    "binned_ages = pd.cut(ages, bins, right=False) # default intervals are (18,25], with right=False they become [18,25)\n",
    "# or\n",
    "binned_ages = pd.cut(ages, bins, labels=groups_names)\n",
    "# or\n",
    "binned_ages = pd.cut(ages, 4) # if integer given, it takes minimum and maximum values and divides that interval in equal sized bins (4 in this case)\n",
    "\n",
    "binned_ages.codes # returns indexes of the bins, only if binned_ages is of type Categorical\n",
    "\n",
    "binned_ages.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So to bin a numerical feature\n",
    "df['feature'] = pd.cut(df['feature'], 4)\n",
    "# if you want to assign labels\n",
    "df['feature'] = pd.cut(df['feature'], 4, labels=groups_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4eac4",
   "metadata": {},
   "source": [
    "## Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features with Ordinal Encoder\n",
    "cat_features = [col for col in df.columns if df[col].dtype == object]\n",
    "ord_enc = preprocessing.OrdinalEncoder()\n",
    "ord_enc.fit(df.loc[:, cat_features])\n",
    "enc_features = ord_enc.transform(df.loc[:, cat_features])\n",
    "df.loc[:, cat_features] = enc_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e485d",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc7b22",
   "metadata": {},
   "source": [
    "### Plot in a bar chart the value distribution of the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pandas\n",
    "df['target'].value_counts().plot(kind='bar')\n",
    "# with seaborn\n",
    "sns.countplot(x = df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d01b2",
   "metadata": {},
   "source": [
    "# Transformation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226be14",
   "metadata": {},
   "source": [
    "## X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target_col'], axis=1)\n",
    "y = df['target_col']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5e546",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fe72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y)  # default test_size=0.25, train_size=0.75\n",
    "# or\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.4)\n",
    "# or\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y) # to keep the same distribution of target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b36019",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81f85d",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default axis=0, standardize each feature.\n",
    "scaler = preprocessing.StandardScaler()         # After, the features have mean=0 and stddev=1\n",
    "scaler = preprocessing.MinMaxScaler((0, 1))     # Scales features to a range\n",
    "scaler = preprocessing.RobustScaler()           # If data contains many outliers, this one performs better\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714c9ee",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ea766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default axis=1, normalize each sample.\n",
    "normalizer = preprocessing.Normalizer() # default 'l2'\n",
    "\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249208ef",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e406e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')              # default 'error'\n",
    "enc = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value')  # default 'error'\n",
    "\n",
    "names_cols = X_train.columns\n",
    "\n",
    "X_train = enc.fit_transform(X_train)\n",
    "X_test = enc.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=names_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder only works with 1-d arrays\n",
    "categorical_cols = [col for col in df.columns if df[col].dtype == object]\n",
    "enc = preprocessing.LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = enc.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28ce83",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discr = preprocessing.KBinsDiscretizer(n_bins=5)\n",
    "discr = preprocessing.KBinsDiscretizer(n_bins=[4, 3, 5]) # 4 bins for feature1, 3 bins for feature2 and 5 bins for feature3 of input X. Input X must have 3 features.\n",
    "discr = preprocessing.KBinsDiscretizer(encode='onehot')\n",
    "discr = preprocessing.KBinsDiscretizer(strategy='uniform')\n",
    "\n",
    "X_train = discr.fit_transform(X_train)\n",
    "X_test = discr.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2257e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarizer\n",
    "discr = preprocessing.Binarizer(threshold=0)\n",
    "\n",
    "X_train = discr.fit_transform(X_train)\n",
    "X_test = discr.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c45b37",
   "metadata": {},
   "source": [
    "## Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPERVISED\n",
    "# classification\n",
    "model = linear_model.LogisticRegression(penalty='l2')\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')  # weights='distance'\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model = ensemble.RandomForestClassifier(n_estimators=100, criterion='gini')\n",
    "model = svm.SVC(kernel='rbf', C=1, gamma='scale')\n",
    "model = dummy.DummyClassifier(strategy='uniform') # only for testing rules of thumb\n",
    "\n",
    "# regression\n",
    "model = linear_model.LinearRegression()\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors=5, weights='uniform')  # weights='distance'\n",
    "model = tree.DecisionTreeRegressor(criterion='squared_error')\n",
    "model = ensemble.RandomForestRegressor(n_estimators=100, criterion='squared_error')\n",
    "model = dummy.DummyRegressor(strategy='mean') # only for testing rules of thumb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cd90b",
   "metadata": {},
   "source": [
    "## Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X=X_test)\n",
    "y_prob = model.predict_proba(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4665b8a",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of grid search for SVC classifier. Obviously, parameters change with the model.\n",
    "parameters = [\n",
    "                {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "                {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "            ]\n",
    "model = svm.SVC()\n",
    "scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "gridsearch = model_selection.GridSearchCV(estimator=model, param_grid=parameters, scoring=scores, cv=5)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print('CV results\\n', gridsearch.cv_results_)\n",
    "print('Best params:', gridsearch.best_params_)\n",
    "print('Best estimator:', gridsearch.best_estimator_)\n",
    "print('Best score:', gridsearch.best_score_)\n",
    "\n",
    "y_pred = gridsearch.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938d5fe",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b46968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with one hot encoder and standard scaler\n",
    "X = df.drop(['target_col'], axis=1)\n",
    "y = df['target_col']\n",
    "categorical_features = [col for col in X.columns if X[col].dtype == object]\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y)\n",
    "\n",
    "coltran = compose.ColumnTransformer(transformers=[(\"onehot\", preprocessing.OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "                                                  (\"std\", preprocessing.StandardScaler(), numerical_features)],\n",
    "                                                  remainder='passthrough')\n",
    "\n",
    "my_pipeline = pipeline.Pipeline(steps=[(\"coltran\", coltran),\n",
    "                                       (\"estimator\", ensemble.RandomForestRegressor())])\n",
    "\n",
    "my_pipeline.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = my_pipeline.predict(X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with k bins discretizer and standard scaler\n",
    "coltran = compose.ColumnTransformer(transformers=[('discr', preprocessing.KBinsDiscretizer(n_bins=5), ['feature1', 'feature3', 'feature4']),\n",
    "                                                  ('std', preprocessing.StandardScaler(), ['feature5', 'feature6'])],\n",
    "                                    remainder='passthrough')\n",
    "\n",
    "my_pipeline = pipeline.Pipeline(steps=[('coltran', coltran),\n",
    "                                    ('estimator', ensemble.RandomForestClassifier())])\n",
    "\n",
    "my_pipeline.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = my_pipeline.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of pipeline\n",
    "coltran = compose.ColumnTransformer(transformers=[('discr', preprocessing.KBinsDiscretizer(n_bins=5), ['feature1', 'feature3', 'feature4']),\n",
    "                                                  ('std', preprocessing.StandardScaler(), ['feature5', 'feature6'])],\n",
    "                                    remainder='passthrough')\n",
    "\n",
    "my_pipeline = pipeline.Pipeline(steps=[('coltran', coltran),\n",
    "                                    ('estimator', ensemble.RandomForestRegressor())])\n",
    "\n",
    "my_pipeline.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = my_pipeline.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc724d",
   "metadata": {},
   "source": [
    "### Grid search with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of grid search with a pipeline\n",
    "# Select categorical columns\n",
    "categorical_cols = [cname for cname in X_train.columns if X_train[cname].dtype == \"object\"]\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = impute.SimpleImputer(strategy='most_frequent')\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore', sparse_output = False))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = compose.ColumnTransformer(\n",
    "    transformers=[\n",
    "       ('num', numerical_transformer, numerical_cols),\n",
    "       ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "model = ensemble.RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = pipeline.Pipeline(steps=[\n",
    "                              ('preprocessor', preprocessor),\n",
    "                              ('model', model),\n",
    "                             ])\n",
    "\n",
    "parameters = {\n",
    "    'model__n_estimators': [1,5,10],\n",
    "    'preprocessor__num__strategy': ['most_frequent','constant','mean'],\n",
    "    'preprocessor__cat__imputer__strategy': ['most_frequent','constant'],\n",
    "}\n",
    "\n",
    "gridsearch = model_selection.GridSearchCV(my_pipeline, parameters, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f59137",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dab990",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Balanced Accuracy:\", metrics.balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"Brier Score Loss:\", metrics.brier_score_loss(y_test, y_prob))\n",
    "print(\"Neg Log Loss:\", metrics.log_loss(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Jaccard:\", metrics.jaccard_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "print('Roc Auc Score:', metrics.roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# print('example: {:0.2f}'.format(statistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc Curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "print(fpr, tpr, thresholds)\n",
    "\n",
    "plt.plot(fpr, tpr,'r-',label = 'Test')\n",
    "#plt.plot([0,1],[0,1],'k-',label='Random')\n",
    "#plt.plot([0,0,1,1],[0,1,1,1],'g-',label='Perfect')\n",
    "plt.legend()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359bd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tp, fn, fp, tn = cnf_matrix.ravel()\n",
    "print('True Positive:', tp)\n",
    "print('True Negative:', tn)\n",
    "print('False Positive:', fp)\n",
    "print('False Negative:', fn)\n",
    "\n",
    "# plot\n",
    "sns.heatmap(cnf_matrix,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b3f6b",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Explained variance score:', metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', metrics.root_mean_squared_error(y_test, y_pred))\n",
    "print('MSLE:', metrics.mean_squared_log_error(y_test, y_pred))\n",
    "print('MedAE:', metrics.median_absolute_error(y_test, y_pred))\n",
    "print('R2 Score:', metrics.r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
